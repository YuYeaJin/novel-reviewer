import streamlit as st
import tempfile
import os
import sys
from dotenv import load_dotenv

# =========================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# =========================
load_dotenv()

# =========================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
# =========================
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

# =========================
# ë‚´ë¶€ ëª¨ë“ˆ import
# =========================
from utils.file_handler import load_from_file, load_from_text_input
from pipeline.langgraph_pipeline import run_langgraph_pipeline


# =========================
# ê³µí†µ ì¶œë ¥ í¬ë§· í•¨ìˆ˜
# =========================
def format_value(v):
    """ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬/ë‹¨ì¼ ê°’ì„ ì‚¬ëŒì´ ì½ê¸° ì¢‹ê²Œ ë³€í™˜"""
    if v is None:
        return None
    if isinstance(v, list):
        return ", ".join(map(str, v))
    if isinstance(v, dict):
        return ", ".join(f"{k}: {format_value(val)}" for k, val in v.items())
    return str(v)


# =========================
# ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
# =========================
def render_result(result: dict):
    st.markdown("---")

    # =========================
    # 1. ìš”ì•½
    # =========================
    st.subheader("âœï¸ ìš”ì•½")

    summary = result.get("summary") or result.get("summary_result") or {}

    paras = summary.get("paragraph_summaries") or summary.get("paragraphs") or []

    summary_text = (
        summary.get("full_summary")
        or summary.get("overall_summary")
        or summary.get("summary_text")
        or summary.get("text")
    )

    if summary_text:
        st.write(summary_text)
    elif paras:
        st.write(" ".join(paras))
    else:
        st.caption("ìš”ì•½ ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    with st.expander("ë¬¸ë‹¨ ìš”ì•½ ìì„¸íˆ ë³´ê¸°"):
        if paras:
            for i, p in enumerate(paras, 1):
                st.markdown(f"**{i}.** {p}")
        else:
            st.caption("ë¬¸ë‹¨ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")

    keywords = summary.get("keywords") or []
    if keywords:
        st.markdown("**í•µì‹¬ í‚¤ì›Œë“œ**")
        st.write(format_value(keywords))

    # =========================
    # 2. ì¥ë¥´ ë¶„ì„
    # =========================
    st.markdown("---")
    st.subheader("ğŸ­ ì¥ë¥´ ë¶„ì„")

    genre = result.get("genre") or {}

    main = genre.get("ì£¼_ì¥ë¥´")
    subs = genre.get("ë³´ì¡°_ì¥ë¥´") or []
    keywords = genre.get("í•µì‹¬_í‚¤ì›Œë“œ") or []
    confidence = genre.get("ì¥ë¥´_ë¶„ë¥˜_ì‹ ë¢°ë„")

    if main:
        st.write(f"- **ì£¼ ì¥ë¥´**: {main}")

    if subs:
        st.write(f"- **ë³´ì¡° ì¥ë¥´**: {', '.join(subs)}")

    if keywords:
        st.write(f"- **í•µì‹¬ í‚¤ì›Œë“œ**: {', '.join(keywords)}")

    if confidence is not None:
        st.write(f"- **ì¥ë¥´ ë¶„ë¥˜ ì‹ ë¢°ë„**: {confidence}")

    if not any([main, subs, keywords, confidence]):
        st.caption("ì¥ë¥´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # =========================
    # 3. ë¬¸ì²´ ë¶„ì„
    # =========================
    st.markdown("---")
    st.subheader("ğŸ–‹ï¸ ë¬¸ì²´ ë¶„ì„")

    style = result.get("style") or result.get("style_result") or {}

    if style:
        for k, v in style.items():
            value_text = format_value(v)
            if value_text:
                st.write(f"- **{k}**: {value_text}")
    else:
        st.caption("ë¬¸ì²´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # =========================
    # 4. ì¢…í•© í‰ê°€
    # =========================
    st.markdown("---")
    st.subheader("ğŸ“Š ì¢…í•© í‰ê°€")

    evaluation = result.get("evaluation") or result.get("evaluation_result") or {}

    summary_eval = (
        evaluation.get("overall_evaluation")
        or evaluation.get("summary")
        or evaluation.get("total_comment")
    )

    if summary_eval:
        st.write(summary_eval)

    for k, v in evaluation.items():
        if k in ("overall_evaluation", "summary", "total_comment"):
            continue
        value_text = format_value(v)
        if value_text:
            st.write(f"- **{k}**: {value_text}")

    if not evaluation:
        st.caption("í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # =========================
    # 5. ìºë¦­í„° ì¹´ë“œ
    # =========================
    st.markdown("---")
    st.subheader("ğŸ‘¤ ìºë¦­í„° ì¹´ë“œ")

    cards = result.get("character_cards") or []

    if cards:
        for c in cards:
            name = c.get("name", "ì´ë¦„ ë¯¸ìƒ")
            role = c.get("role")

            st.markdown(f"### {name}" + (f" ({role})" if role else ""))

            personality = c.get("personality_keywords") or []
            if personality:
                st.write(f"- **ì„±ê²© í‚¤ì›Œë“œ**: {', '.join(personality)}")

            core_traits = c.get("core_traits")
            if core_traits:
                st.write(f"- **í•µì‹¬ ì„±í–¥**: {core_traits}")

            warning = c.get("warning_point")
            if warning:
                st.write(f"- **ì£¼ì˜ í¬ì¸íŠ¸**: {warning}")
    else:
        st.caption("ìºë¦­í„° ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # =========================
    # 6. ì›ë³¸ JSON
    # =========================
    st.markdown("---")
    with st.expander("ğŸ” ì›ë³¸ JSON ë³´ê¸° (ë””ë²„ê¹…)"):
        st.json(result)


# =========================
# í…ìŠ¤íŠ¸ ë¡œë”© í•¨ìˆ˜
# =========================
def load_text(uploaded_file, input_text):
    if uploaded_file:
        suffix = os.path.splitext(uploaded_file.name)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.getbuffer())
            path = tmp.name
        try:
            return load_from_file(path)
        finally:
            os.remove(path)

    if input_text.strip():
        return load_from_text_input(input_text)

    return ""


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="Novel Reviewer", layout="wide")

st.title("Novel Reviewer")
st.caption("LangGraph ê¸°ë°˜ ì›¹ì†Œì„¤ ë¶„ì„ AI Agent")

# 1. ì›ê³  ì…ë ¥
st.header("1. ì›ê³  ì…ë ¥")

uploaded_file = st.file_uploader(
    "íŒŒì¼ ì—…ë¡œë“œ (txt / pdf / docx)",
    type=["txt", "pdf", "docx"],
)

input_text = st.text_area(
    "ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥",
    height=250,
    placeholder="ë¶„ì„í•  ì†Œì„¤ ì›ê³ ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
)

text = load_text(uploaded_file, input_text)

if not text:
    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# 2. ë¶„ì„ ì‹¤í–‰
st.header("2. ë¶„ì„ ì‹¤í–‰")

if st.button("ì›¹ì†Œì„¤ ì¢…í•© ë¶„ì„"):
    with st.spinner("LangGraph AI Agentê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        result = run_langgraph_pipeline(text)

    # text_type ë¨¼ì € í™•ì¸
    text_type = result.get("text_type")

    if text_type and text_type.get("type") == "unknown":
        # ì´ìœ  ë©”ì‹œì§€ ì¶œë ¥
        st.warning(
            text_type.get(
                "message",
                "ë¶„ì„í•  ìˆ˜ ì—†ëŠ” ì…ë ¥ì…ë‹ˆë‹¤."
            )
        )
        # ì•„ë˜ UI ì „ë¶€ ì¤‘ë‹¨
        st.stop()

    # ì •ìƒ ë¶„ì„ì¼ ë•Œë§Œ
    st.success("ë¶„ì„ ì™„ë£Œ")

    # 3. ë¶„ì„ ê²°ê³¼
    st.header("3. ë¶„ì„ ê²°ê³¼")
    render_result(result)

