import streamlit as st
import tempfile
import os
import sys
from dotenv import load_dotenv

# =========================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# =========================
load_dotenv()

# =========================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
# =========================
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

# =========================
# ë‚´ë¶€ ëª¨ë“ˆ import
# =========================
from utils.file_handler import load_from_file, load_from_text_input
from pipeline.langgraph_pipeline import run_langgraph_pipeline


# =========================
# ê³µí†µ ì¶œë ¥ í¬ë§· í•¨ìˆ˜
# =========================
def format_value(v):
    """ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬/ë‹¨ì¼ ê°’ì„ ì‚¬ëŒì´ ì½ê¸° ì¢‹ê²Œ ë³€í™˜"""
    if v is None:
        return None
    if isinstance(v, list):
        return ", ".join(map(str, v))
    if isinstance(v, dict):
        return ", ".join(f"{k}: {format_value(val)}" for k, val in v.items())
    return str(v)


# =========================
# ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
# =========================
def render_result(result: dict):
    st.markdown("---")

    # =========================
    # 1. ìš”ì•½
    # =========================
    st.subheader("âœï¸ ìš”ì•½")

    summary = result.get("summary") or result.get("summary_result") or {}

    paras = summary.get("paragraph_summaries") or summary.get("paragraphs") or []

    summary_text = (
        summary.get("full_summary")
        or summary.get("overall_summary")
        or summary.get("summary_text")
        or summary.get("text")
    )

    if summary_text:
        st.write(summary_text)
    elif paras:
        st.write(" ".join(paras))
    else:
        st.caption("ìš”ì•½ ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    with st.expander("ë¬¸ë‹¨ ìš”ì•½ ìì„¸íˆ ë³´ê¸°"):
        if paras:
            for i, p in enumerate(paras, 1):
                st.markdown(f"**{i}.** {p}")
        else:
            st.caption("ë¬¸ë‹¨ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")

    keywords = summary.get("keywords") or []
    if keywords:
        st.markdown("**í•µì‹¬ í‚¤ì›Œë“œ**")
        st.write(format_value(keywords))

    # =========================
    # 2. ì¥ë¥´ ë¶„ì„
    # =========================
    st.markdown("---")
    st.subheader("ğŸ­ ì¥ë¥´ ë¶„ì„")

    genre = result.get("genre") or result.get("genre_result") or {}

    main = genre.get("main_genre") or genre.get("primary_genre")
    sub = genre.get("sub_genre") or genre.get("secondary_genre")
    confidence = genre.get("confidence") or genre.get("confidence_score")

    if main:
        st.write(f"- **ì£¼ ì¥ë¥´**: {format_value(main)}")
    if sub:
        st.write(f"- **ë³´ì¡° ì¥ë¥´**: {format_value(sub)}")
    if confidence is not None:
        st.write(f"- **ì‹ ë¢°ë„**: {format_value(confidence)}")

    if not any([main, sub, confidence]):
        st.caption("ì¥ë¥´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # =========================
    # 3. ë¬¸ì²´ ë¶„ì„
    # =========================
    st.markdown("---")
    st.subheader("ğŸ–‹ï¸ ë¬¸ì²´ ë¶„ì„")

    style = result.get("style") or result.get("style_result") or {}

    if style:
        for k, v in style.items():
            value_text = format_value(v)
            if value_text:
                st.write(f"- **{k}**: {value_text}")
    else:
        st.caption("ë¬¸ì²´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # =========================
    # 4. ì¢…í•© í‰ê°€
    # =========================
    st.markdown("---")
    st.subheader("ğŸ“Š ì¢…í•© í‰ê°€")

    evaluation = result.get("evaluation") or result.get("evaluation_result") or {}

    summary_eval = (
        evaluation.get("overall_evaluation")
        or evaluation.get("summary")
        or evaluation.get("total_comment")
    )

    if summary_eval:
        st.write(summary_eval)

    for k, v in evaluation.items():
        if k in ("overall_evaluation", "summary", "total_comment"):
            continue
        value_text = format_value(v)
        if value_text:
            st.write(f"- **{k}**: {value_text}")

    if not evaluation:
        st.caption("í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # =========================
    # 5. ìºë¦­í„° ì¹´ë“œ
    # =========================
    st.markdown("---")
    st.subheader("ğŸ‘¤ ìºë¦­í„° ì¹´ë“œ")

    cards = (
        result.get("character_cards")
        or result.get("character_card")
        or result.get("character_card_result")
        or []
    )

    if cards:
        for c in cards:
            if not isinstance(c, dict):
                continue

            name = c.get("name") or c.get("character_name") or "ì´ë¦„ ë¯¸ìƒ"
            role = c.get("role") or c.get("importance")

            st.markdown(f"### {name}" + (f" ({role})" if role else ""))

            desc = (
                c.get("description")
                or c.get("summary")
                or c.get("character_description")
            )
            if desc:
                st.write(format_value(desc))
    else:
        st.caption("ìºë¦­í„° ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # =========================
    # 6. ì›ë³¸ JSON
    # =========================
    st.markdown("---")
    with st.expander("ğŸ” ì›ë³¸ JSON ë³´ê¸° (ë””ë²„ê¹…)"):
        st.json(result)


# =========================
# í…ìŠ¤íŠ¸ ë¡œë”© í•¨ìˆ˜
# =========================
def load_text(uploaded_file, input_text):
    if uploaded_file:
        suffix = os.path.splitext(uploaded_file.name)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.getbuffer())
            path = tmp.name
        try:
            return load_from_file(path)
        finally:
            os.remove(path)

    if input_text.strip():
        return load_from_text_input(input_text)

    return ""


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="Novel Reviewer", layout="wide")

st.title("Novel Reviewer")
st.caption("LangGraph ê¸°ë°˜ ì›¹ì†Œì„¤ ë¶„ì„ AI Agent")

# 1. ì›ê³  ì…ë ¥
st.header("1. ì›ê³  ì…ë ¥")

uploaded_file = st.file_uploader(
    "íŒŒì¼ ì—…ë¡œë“œ (txt / pdf / docx)",
    type=["txt", "pdf", "docx"],
)

input_text = st.text_area(
    "ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥",
    height=250,
    placeholder="ë¶„ì„í•  ì†Œì„¤ ì›ê³ ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
)

text = load_text(uploaded_file, input_text)

if not text:
    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# 2. ë¶„ì„ ì‹¤í–‰
st.header("2. ë¶„ì„ ì‹¤í–‰")

if st.button("ì›¹ì†Œì„¤ ì¢…í•© ë¶„ì„"):
    with st.spinner("LangGraph AI Agentê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        result = run_langgraph_pipeline(text)

    st.success("ë¶„ì„ ì™„ë£Œ")

    # 3. ë¶„ì„ ê²°ê³¼
    st.header("3. ë¶„ì„ ê²°ê³¼")
    render_result(result)
